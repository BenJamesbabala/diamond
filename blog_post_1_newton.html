<!DOCTYPE html>
<html>

<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>blog_post_1_newton</title>


<style type="text/css">
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
  font-size: 28px;
  color: black; }

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black; }

h3 {
  font-size: 18px; }

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; }

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}

kbd {
  display: inline-block;
  padding: 3px 5px;
  font-size: 11px;
  line-height: 10px;
  color: #555;
  vertical-align: middle;
  background-color: #fcfcfc;
  border: solid 1px #ccc;
  border-bottom-color: #bbb;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #bbb
}

* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}
</style>


</head>

<body>

<p>Many computational problems in data science and statistics can be cast as convex problems. There are many advantages to doing so:</p>

<ul>
<li>Convex problems have a unique global solution, i.e. there is one best answer</li>
<li>There are well-known, efficient, and reliable algorithms for finding it</li>
</ul>

<p>One ubiquitous example of a convex problem in data science is finding the coefficients of an \(L_2\)-regularized logistic regression model using maximum likelihood. In this post, we&#39;ll talk about some basic algorithms for convex optimization, and discuss our attempts to make them scale up to the size of our models. Unlike many applications, the &quot;scale&quot; challenge we faced was not the number of observations, but the number of features in our datasets. First, let&#39;s review the model we want to fit.</p>

<h2 id="toc_0">\(L_2-\)regularized logistic regression</h2>

<p>Suppose we have observed \(N\) obersations like \((x_i, y_i)\) where \(x_i\) is a <em>p</em>-vector of covariates for observation \(i\) and \(y_i\) is its binary outcome coded as 0/1. We wish to fit this model via maximum likelihood, which means
\[ \max_{\beta} L(y | X, \beta) = \prod_{i=1}^N Pr(y_i=1|x_i)^{y_i} (1 - Pr(y_i=1))^{1 - y_i} \]
where
\[ Pr(y_i = 1 | \beta, x_i) = \frac{1}{1 + exp(-\beta^T x_i )} \]
For numerical reasons, we prefer to <em>minimize</em> the negative log-likelihood instead of <em>maximizing</em> the likelihood. Additionally, we&#39;ll add an \(L_2\) penalty term, \(P\), which corresponds to a \(N(0, P^{-1})\) multivariate Gaussian prior on \(\beta\) (see derivation <a href="https://stats.stackexchange.com/questions/163388/l2-regularization-is-equivalent-to-gaussian-prior">here</a>). Therefore, we wish to find a \(\beta\) to minimize
\[ \sum_{i=1}^N -y_i log Pr(y_i=1|x_i) - (1 - y_i) log (1 - Pr(y_i=1)) + \frac{1}{2}\beta^T P \beta \]</p>

<p>We tried a few techniques to estimate \(\beta\), starting with the simplest.</p>

<h2 id="toc_1">Gradient descent</h2>

<p>The first approach we tried was <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a>. For the simplest version of gradient descent, all we need is to compute the derivative of the function we wish to minimize, and choose a step size, \(\gamma\). Then, at each iteration, we update according to this rule:
\[ \beta_{t+1} = \beta_t - \gamma \nabla_t \]</p>

<p>For our problem, the gradient is
\[ \nabla_t = \sum\limits_{i=1}^N x_i (p_i - y_i) + P \beta_t \]</p>

<p>Since our negative loglikelihood function is convex, under some mild conditions on \(\gamma\), this algorithm is guaranteed to converge to the global optimimum, <em>eventually</em>. Gradient descent is nice because it&#39;s</p>

<ul>
<li>Simple. This means:

<ul>
<li>easy to code!</li>
<li>easy to test!</li>
<li>easy to debug!</li>
</ul></li>
<li>General: works on a wide variety of problems</li>
<li>A slight variant of this, <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a>, scales to very, very large training data sets. However, our problem was scaling to a large number of features.</li>
</ul>

<p>Unfortunately, we found gradient descent to be too slow for the number of parameters we wanted to estimate. So we tried another classic optimization algorithm, Newton&#39;s Method.</p>

<h2 id="toc_2">Newton&#39;s Method</h2>

<p>You might remember this from undergraduate calculus, but if it&#39;s been a while here&#39;s a quick refresher.</p>

<h3 id="toc_3">Reminder of Newton&#39;s method: Finding Zeros of a 1D Function</h3>

<p>To illustrate Newton&#39;s method, let&#39;s start with a very simple problem: find an \(x\) such that \(f(x) = 0\). To do this, Newton&#39;s method uses a linear approximation of \(f\) that goes like this.</p>

<ul>
<li>Choose an arbitrary starting point on the curve \(x_0\)</li>
<li>Find the tangent to the curve at \(x_0\), and trace it down to the x axis</li>
<li>Repeat the process with the new x value being the point where the tangent crossed the x axis.</li>
</ul>

<p><img src="blog_post_1_image_1.png" alt="newton zeros"></p>

<p>Mathematically, the update rule is</p>

<p>\(x_{t+1} = x_t - \frac{f(x_t)}{f&#39;(x_t)}\)</p>

<p>As with most iterative algorithms, we repeat this until the change, \(|x_{t+1} - x_t| &lt; \epsilon\) for some predefined tolerance parameter \(\epsilon\).</p>

<h3 id="toc_4">Simple optimization</h3>

<p>What does this have to do with optimization, you ask? Well, for convex functions, we&#39;re looking for the global minimum \(x^*\), and we know that \(f&#39;(x^*) = 0\). So we can use the algorithm we just described not on \(f\), but on \(f&#39;\), in order to find \(x^*\). Concretely, this means using a linear approximation to \(f&#39;(x)\) at each iteration, and therefore a quadratic approximation to \(f(x)\).</p>

<p><img src="blog_post_1_image_2.png" alt="newton 1d optimization"></p>

<p>Mathematically, the update rule is</p>

<p>\(x_{t+1} = x_t - \frac{f&#39;(x_t)}{f&#39;&#39;(x_t)}\)</p>

<p>Again, we repeat this iterative algorithm until some stopping condition is met. Common rules are</p>

<ul>
<li>\(|x_{t+1} - x_t| &lt; \epsilon_x\), i.e. our parameter changes less than some predefined amount</li>
<li>\(|f(x_{t+1}) - f(x_t)| &lt; \epsilon_f\), i.e. our objective function changes less than some predefined amount</li>
<li>stop after a set number of iterations, no matter what</li>
</ul>

<h2 id="toc_5">Newton&#39;s method applied to logistic regression</h2>

<p>In vector notation, one iteration of Newton&#39;s method is
\[ x_{t+1} = x_t - H^{-1}_t\nabla_t \]</p>

<p>When we use Newton&#39;s method to find the parameters of a logistic regression problem, we&#39;re using an algorithm known as iteratively reweighted least squares (IRLS). R users will recognize this as the default method for fitting generalized linear models in <code>glm</code>. Unfortunately, inverting the Hessian matrix at every iteration does not scale will with the number of parameters, so we also found this method inadequate in its simplest form. However, with a couple of tricks, we were able to make it work. These tricks came from <a href="https://tminka.github.io/papers/logreg/minka-logreg.pdf">this paper</a> by Thomas Minka, to which we are greatly indebted.</p>

<h3 id="toc_6">Fixed-Hessian</h3>

<p>It&#39;s possible to compute and invert the Hessian once, and then use it in place of the true Hessian at every iteration. Let&#39;s call our approximate Hessian \(\tilde H\). As long as \(H - \tilde H\) is positive definite, this is guaranteed to converge (see Minka&#39;s paper for a proof). For an arbitrary penalty matrix \(P\), a good choice is
\[ \tilde H = -\frac{1}{4} X X^T - P \]</p>

<p>This leads to the following update rule:
\[ \beta_{t+1} = \beta_t - \tilde H^{-1}\nabla_t \]</p>

<h3 id="toc_7">Conjugate gradient trick</h3>

<p>In practice, it&#39;s faster to take \(u = -\tilde H^{-1}\nabla\) as a step direction, and then use the conjugate gradient method to determine a step size \(\gamma\). Mathematically, our update rule will be </p>

<p>\[ u = \tilde H^{-1}\nabla \]
\[ \beta_t = \beta_{t-1} - \gamma u\]</p>

<p>where \(\gamma \in \mathbb{R}\). To determine how large of a step we should take, consider the second-order Taylor expansion of our penalized, negative loglikelihood function \(f\) around a point \(\beta_0\):</p>

<p>\(f(\beta) \approx f(\beta_0) + \nabla_0^T(\beta - \beta_0) + \frac{1}{2}(\beta - \beta_0)^TH_0(\beta - \beta_0)\)</p>

<p>Now, let&#39;s optimize this function with respect to our step size \(\gamma\) by taking its derivative, setting it equal to zero, and solving.
\[ \frac{\partial f}{\partial \gamma} = (\nabla f(\beta))^T (-u) \]
\[ \frac{\partial f}{\partial \gamma} = (H_0\beta + \nabla_0 - H_0\beta_0)^T(-u) \]
\[ \frac{\partial f}{\partial \gamma} = (H_0(\beta_0 - \gamma u) + \nabla_0 - H_0\beta_0)^T(-u) \]
\[ \frac{\partial f}{\partial \gamma} = (- \gamma H_0 u + \nabla_0)^T(-u) \]
Now, set equal to 0 and solve for \(\gamma\). Note that H is symmetric, so \(H^T = H\)
\[ 0 = (- \gamma H_0 u + \nabla_0)^T(-u) \]
\[ 0 = \gamma u^T H_0^T u - \nabla_0^T u \]
\[ \gamma =  \frac{\nabla_0^T u}{u^T H_0 u} \]</p>

<p>Since H is positive definite, this is a minimum of f in the neighborhood of \(\beta_0\), which is what we want, since we are minimizing the negative, penalized log-likelihood. </p>

<h2 id="toc_8">Mixed-effects models</h2>

<p>An important class of this kind of model is mixed effects (see blog post #2). In this case, the key idea is that we can <em>almost</em> separate the optimization problem across levels of the random effects. But the fixed effects are common to the model for each level, so we can&#39;t really separate the problem. This does, however, suggest a strategy that alternates between two stages:</p>

<ol>
<li>solve for fixed effects coefficients</li>
<li>solve for random effects coefficients with the fixed effects from (1) treated as constants</li>
</ol>

<p>Because the whole problem is convex, this alternating iteration will converge to the global optimum. This is numerically possible because we can store the Hessian as a sparse, block diagonal matrix and thus afford to invert it. This lets us use the quasi-Newton method described above. With this methodology, we can fit models with millions of random effect levels. In principle, one could also separate the problem in (2) across levels and solve them in parallel, potentially making it faster still.</p>

<h2 id="toc_9">Conclusion</h2>

<p>With these two tricks, we have written a very fast, Newton-inspired, implementation of this algorithm in Python 2.7 for logistic (binary outcome) and cumulative logistic (ordinal outcome) regression with very general \(L_2\) regularization. Our use case is mixed-effects models with tens of thousands of parameters. Our implementation is called <a href="https://github.com/stitchfix/diamond">diamond</a>, and we are going to open-source it soon. Stay tuned!</p>

<h2 id="toc_10">Sources</h2>

<ul>
<li><a href="http://web.stanford.edu/%7Eboyd/cvxbook/">Boyd and Vandenberghe&#39;s book</a> is a wonderful reference on convex optimization</li>
<li><a href="https://tminka.github.io/papers/logreg/minka-logreg.pdf">Minka</a> provided the necessary tweaks to make Newton&#39;s method work for this particular problem</li>
<li>Thanks to Brad Klingenberg, PhD for mentorship on this project</li>
</ul>



<script type="text/x-mathjax-config">
(function () {

MathJax.Hub.Config({
	'showProcessingMessages': false,
	'messageStyle': 'none'
});

if (typeof MathJaxListener !== 'undefined') {
	MathJax.Hub.Register.StartupHook('End', function () {
		MathJaxListener.invokeCallbackForKey_('End');
	});
}

})();
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


</body>

</html>
